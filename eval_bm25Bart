#!/usr/bin/bash

python run_modified_summarization.py \
	--model_name_or_path './BART-Pubmed_summarizer' \
	--do_eval \
	--dataset_name ccdv/pubmed-summarization \
	--summary_column abstract \
	--text_column article \
	--generation_max_length=200 \
	--per_device_eval_batch_size=20 \
	--predict_with_generate \
	--output_dir ./BARTBM25-Pubmed_eval


# ***** eval metrics ***** 100 examples (Base)
#   eval_gen_len            =     126.39
#   eval_loss               =     2.1131
#   eval_rouge1             =    17.5051
#   eval_rouge2             =     1.4327
#   eval_rougeL             =    10.7089
#   eval_rougeLsum          =    15.8872
#   eval_runtime            = 0:16:31.42
#   eval_samples            =        100
#   eval_samples_per_second =      0.101
#   eval_steps_per_second   =      0.005

# ***** eval metrics *****
#   eval_gen_len            =     126.39
#   eval_loss               =     2.1131
#   eval_rouge1             =    19.9489
#   eval_rouge2             =     1.4875
#   eval_rougeL             =    11.0795
#   eval_rougeLsum          =    16.8198
#   eval_runtime            = 0:16:37.16
#   eval_samples            =        100
#   eval_samples_per_second =        0.1
#   eval_steps_per_second   =      0.005





# ***** eval metrics ***** Textrank method whole
#   eval_gen_len            =   127.9403
#   eval_loss               =     2.1627
#   eval_rouge1             =    19.6727
#   eval_rouge2             =     1.4118
#   eval_rougeL             =    11.0739
#   eval_rougeLsum          =    16.5916
#   eval_runtime            = 0:47:17.77
#   eval_samples            =       6630
#   eval_samples_per_second =      2.336
#   eval_steps_per_second   =      0.117

#include short summary and include regular textrank

#Look into shorter summaries (User study)

#Write section 3 (Methodology/Approach) Wednesday next week

#https://github.com/clulab/clulab/wiki/Structure-of-Academic-Papers-&--Common-Writing-Issues
#https://doodle.com/meeting/participate/id/b6RqP1lb

# ***** eval metrics ***** base
#   eval_gen_len            =   127.9403
#   eval_loss               =     2.1627
#   eval_rouge1             =    17.4902
#   eval_rouge2             =     1.4119
#   eval_rougeL             =    10.8816
#   eval_rougeLsum          =    15.9118
#   eval_runtime            = 0:46:54.03
#   eval_samples            =       6630
#   eval_samples_per_second =      2.356
#   eval_steps_per_second   =      0.118


# ***** eval metrics ***** New method 200
#   eval_gen_len            =   127.9403
#   eval_loss               =     2.1627
#   eval_rouge1             =     20.026
#   eval_rouge2             =     1.6384
#   eval_rougeL             =    11.8364
#   eval_rougeLsum          =    17.9544
#   eval_runtime            = 0:47:00.51
#   eval_samples            =       6630
#   eval_samples_per_second =      2.351
#   eval_steps_per_second   =      0.118


#textrank
